{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20e5b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets accelerate peft evaluate rouge-score sacrebleu ipywidgets torch\n",
    "\n",
    "import os, torch\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ee17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "MAX_INPUT_LEN, MAX_TARGET_LEN = 128, 224\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "LR_SCHED = \"cosine\"\n",
    "EPOCHS = 2\n",
    "\n",
    "BATCH = 1           # MPS - macbook\n",
    "GRAD_ACC = 16       # batch efetivo 16\n",
    "SAVE_STEPS = 200    # salvar (se necessário retomra) a cada 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90a9af92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48500, 1500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "raw = load_dataset(\"json\", data_files={\"train\":\"../data/train.jsonl\",\"val\":\"../data/val.jsonl\"})\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(batch):\n",
    "    model_inputs = tokenizer(batch[\"input_text\"], max_length=MAX_INPUT_LEN, truncation=True, padding=False)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch[\"target_text\"], max_length=MAX_TARGET_LEN, truncation=True, padding=False)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized = raw.map(preprocess, batched=True, remove_columns=raw[\"train\"].column_names)\n",
    "len(tokenized[\"train\"]), len(tokenized[\"val\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5659da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3561\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
    "model.config.use_cache = False\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "lora_cfg = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, r=8, lora_alpha=16, lora_dropout=0.05, bias=\"none\",\n",
    "                      target_modules=[\"q\",\"v\"])\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f82dda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x15f606210>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"../outputs/t5_lora_mps\",\n",
    "    per_device_train_batch_size=BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACC,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    lr_scheduler_type=LR_SCHED,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=50,\n",
    "    fp16=(device==\"cuda\"),\n",
    "    bf16=False,\n",
    "    **({\"eval_strategy\":\"no\"} if \"eval_strategy\" in inspect.signature(TrainingArguments.__init__).parameters\n",
    "       else {\"evaluation_strategy\":\"no\"})\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    data_collator=data_collator,\n",
    "    **({\"processing_class\": tokenizer}\n",
    "       if \"processing_class\" in inspect.signature(Trainer.__init__).parameters\n",
    "       else {\"tokenizer\": tokenizer})\n",
    ")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f346cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vilella/Documents/fiap/pos_ia/iadt_fase03_final/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6064' max='6064' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6064/6064 3:58:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.651900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.676900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.722400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.775900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.740900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.806300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.854700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.898800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.927100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.917100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.875800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.978100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.942300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>3.926300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.075300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>4.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>4.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>4.169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>4.116300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>4.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>4.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>4.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>4.190900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>4.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.121100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>4.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>4.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>4.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>4.173600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>4.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>4.263400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>4.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>4.204800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>4.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>4.299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>4.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>4.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>4.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>4.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>4.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>4.296200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>4.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>4.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>4.343900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>4.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>4.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>4.370300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>4.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>4.387900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>4.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>4.358800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>4.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.439700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>4.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>4.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>4.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>4.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>4.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>4.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>4.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>4.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>4.472100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.518500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>4.470600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>4.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>4.452900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>4.456700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>4.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>4.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>4.548200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>4.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>4.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.551700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>4.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>4.444200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>4.556400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>4.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>4.483500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>4.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>4.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>4.485700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>4.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>4.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>4.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>4.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>4.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>4.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>4.475400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>4.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>4.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>4.499600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>4.485400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>4.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>4.503800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>4.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>4.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>4.507800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>4.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>4.478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>4.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.459200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>4.517600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 7b84f4bf-98da-499d-8545-ea0d2c921d51)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: eb2d9f6a-de8b-420f-8689-2a04cd45508e)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 4c83466c-119f-499f-8fc1-09230ce39ea1)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a1e205da-e077-4f7f-93a9-a80d313462bf)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 992edd32-6177-482f-972d-3fd55a7af8b7)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f96d49cb-9569-40a6-b6b7-bcec4f5aa6b9)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: fbefe5c0-aba6-42d3-afff-5de25c7e3f42)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e975b9c8-6c2e-4a70-84d8-6c9835e8bbf1)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 931687ee-f77c-4b00-b135-f189843b6150)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 20ccfce7-b9a2-4c6b-b1d6-420070b50128)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 89a278af-34fe-44e7-af13-c18712d7f0ee)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 6d23a521-34de-4990-84de-162366ae134a)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a3795fc6-db0e-4232-9508-698ac0338a20)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 1762e262-4f94-42da-bda7-d18b7892f311)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8cacfc4d-dd41-4a4c-b5d0-350745132fc6)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "/Users/vilella/Documents/fiap/pos_ia/iadt_fase03_final/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a40839f0-e725-4e2b-afb8-1ff30eff883d)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9b6b7535-12a1-4069-a4ab-61f4f1a0d56f)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 78e7a862-f80f-4b5c-af9b-aa755b081f15)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3eaa42c9-0121-4646-b92c-38bbe09c9016)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 58624079-94ba-418d-8e3c-87bdd07fb4fc)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 659e1356-bb54-4c8b-9763-0549c4183705)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 0c034c3a-74e4-4819-a172-db2a85cc5ab0)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3e62f832-0fff-4236-8254-ef748a107131)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 46810283-0d05-4a1f-9148-01dc53bcfc67)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ac462ce3-7b83-4068-b948-20faa8b4cf64)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a84e176b-4c28-41aa-99ef-1d416403a260)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 81072720-2c49-4bbe-a2fc-7177683e9d73)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3597306a-05da-4541-8f6b-85b0a38d0108)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 79092751-ee49-4000-8fe2-857113610f4d)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 112a3e21-7309-490d-b13e-d08c9e2586b3)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6064, training_loss=4.258969286815472, metrics={'train_runtime': 14330.8855, 'train_samples_per_second': 6.769, 'train_steps_per_second': 0.423, 'total_flos': 4365024810854400.0, 'train_loss': 4.258969286815472, 'epoch': 2.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_result = trainer.train(resume_from_checkpoint=True)\n",
    "train_result = trainer.train()\n",
    "train_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f46bc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 7978fec8-c984-4ddc-bc1f-eef1082a66ce)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val(1k) - ROUGE-L: 0.1006 | BLEU: 0.66\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import PeftModel\n",
    "import evaluate, json\n",
    "\n",
    "# textos da validação (cru, com strings)\n",
    "N = min(1000, len(raw[\"val\"]))\n",
    "texts = raw[\"val\"].select(range(N))[\"input_text\"]\n",
    "refs  = raw[\"val\"].select(range(N))[\"target_text\"]\n",
    "\n",
    "# carregar checkpoint campeão\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
    "model_ckpt = PeftModel.from_pretrained(base, \"../outputs/t5_lora_mps/checkpoint-6064\").to(device)\n",
    "\n",
    "# geração leve\n",
    "preds = []\n",
    "with torch.inference_mode():\n",
    "    for x in texts:\n",
    "        enc = tokenizer(x, return_tensors=\"pt\", truncation=True, max_length=MAX_INPUT_LEN).to(device)\n",
    "        out = model_ckpt.generate(**enc, max_new_tokens=MAX_TARGET_LEN, num_beams=1)\n",
    "        preds.append(tokenizer.decode(out[0], skip_special_tokens=True))\n",
    "        if device==\"mps\": torch.mps.empty_cache()\n",
    "\n",
    "rouge = evaluate.load(\"rouge\"); bleu = evaluate.load(\"sacrebleu\")\n",
    "r = rouge.compute(predictions=preds, references=refs, use_aggregator=True)\n",
    "b = bleu.compute(predictions=preds, references=[[y] for y in refs])\n",
    "print(\"Val(1k) - ROUGE-L:\", round(float(r[\"rougeL\"]),4), \"| BLEU:\", round(float(b[\"score\"]),2))\n",
    "\n",
    "# snapshot\n",
    "import os; os.makedirs(\"../outputs\", exist_ok=True)\n",
    "with open(\"../outputs/eval_snapshot.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump({\"checkpoint\":\"checkpoint-9000\",\"rougeL\":float(r[\"rougeL\"]),\"bleu\":float(b[\"score\"])}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9678ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ff5d32f7-2a4a-48fb-8ef3-ddad52da210e)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ff5d32f7-2a4a-48fb-8ef3-ddad52da210e)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare salvo em outputs/compare_baseline_vs_finetuned.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json, gc\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "rows = [json.loads(l) for l in open(\"../outputs/baseline_val200.jsonl\",\"r\",encoding=\"utf-8\")]\n",
    "inputs = [r[\"input\"] for r in rows]\n",
    "refs200 = [r[\"ref\"] for r in rows]\n",
    "\n",
    "def gen_batch(mdl, texts, bs=2):\n",
    "    out=[]\n",
    "    with torch.inference_mode():\n",
    "        for i in range(0,len(texts),bs):\n",
    "            enc = tokenizer(texts[i:i+bs], return_tensors=\"pt\", padding=True,\n",
    "                            truncation=True, max_length=MAX_INPUT_LEN).to(device)\n",
    "            ids = mdl.generate(**enc, max_new_tokens=MAX_TARGET_LEN, num_beams=1)\n",
    "            out += tokenizer.batch_decode(ids, skip_special_tokens=True)\n",
    "            if device==\"mps\": torch.mps.empty_cache()\n",
    "    return out\n",
    "\n",
    "# baseline cru\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
    "preds_bl = gen_batch(base_model, inputs); del base_model; gc.collect()\n",
    "\n",
    "# fine-tuned best\n",
    "preds_ft = gen_batch(model_ckpt, inputs)\n",
    "\n",
    "with open(\"../outputs/compare_baseline_vs_finetuned.jsonl\",\"w\",encoding=\"utf-8\") as f:\n",
    "    for x, pb, pf, y in zip(inputs, preds_bl, preds_ft, refs200):\n",
    "        f.write(json.dumps({\"input\":x,\"baseline_pred\":pb,\"finetuned_pred\":pf,\"ref\":y},ensure_ascii=False)+\"\\n\")\n",
    "print(\"compare salvo em outputs/compare_baseline_vs_finetuned.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31bc6dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: {'rougeL': 0.1223, 'bleu': 0.0003}\n",
      "Fine-tuned: {'rougeL': 0.1123, 'bleu': 0.9039}\n"
     ]
    }
   ],
   "source": [
    "import evaluate, json\n",
    "rows = [json.loads(l) for l in open(\"../outputs/compare_baseline_vs_finetuned.jsonl\",\"r\",encoding=\"utf-8\")]\n",
    "preds_bl = [r[\"baseline_pred\"]  for r in rows]\n",
    "preds_ft = [r[\"finetuned_pred\"] for r in rows]\n",
    "refs200  = [r[\"ref\"]            for r in rows]\n",
    "\n",
    "rouge = evaluate.load(\"rouge\"); bleu = evaluate.load(\"sacrebleu\")\n",
    "def metric(preds, refs):\n",
    "    r = rouge.compute(predictions=preds, references=refs, use_aggregator=True)\n",
    "    b = bleu.compute(predictions=preds, references=[[x] for x in refs])\n",
    "    return {\"rougeL\": float(r[\"rougeL\"]), \"bleu\": float(b[\"score\"])}\n",
    "\n",
    "print(\"Baseline:\", {k: round(v,4) for k,v in metric(preds_bl, refs200).items()})\n",
    "print(\"Fine-tuned:\", {k: round(v,4) for k,v in metric(preds_ft, refs200).items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb2d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1f945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d016142a-8321-41aa-a798-fb5e172274ad)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d016142a-8321-41aa-a798-fb5e172274ad)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final salvo em artifacts/t5_lora_best\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"../artifacts/t5_lora_best\", exist_ok=True)\n",
    "model_ckpt.save_pretrained(\"../artifacts/t5_lora_best\")\n",
    "tokenizer.save_pretrained(\"../artifacts/t5_lora_best\")\n",
    "print(\"Modelo final salvo em artifacts/t5_lora_best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
